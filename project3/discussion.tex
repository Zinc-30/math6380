%!TEX root = nips_2016.tex
\section{Results and Discussion}
We compared two models in four aspects: training loss, training accuracy, validation accuracy, and test score from kaggle. The results are shown in Table 1. \\
\begin{table}[htbp]
\label{result}
\centering
\begin{tabular}{|l|l|l|l|l|}
\hline
model    & training loss & training accuracy & validation accuracy & test score \\
\hline
Original & 59.0390       & 0.9753            & 0.9317              & 0.9418 \\
\hline
Extended & 41.3801       & 0.9858            & 0.9372              & 0.9474 \\
\hline
\end{tabular}
\caption{Experiment results}
\end{table}
From the results in Table 1, the \textit{Extended} model performed better in all four aspects. We believe that this is because the $w_1$ parameter makes the model more flexible, so that it can cross some local optimal regions more easily. We also noticed that the \textit{Extended} model had lower training loss than the \textit{Original} model, while for other three aspects, especially for validation accuracy and test score, these two models had no big differences. We think this can be explained by the difference of model complexity. The \textit{Extended} model is more complex than the \textit{Original} model, so it can fit the training data better, but the accuracy is too high to improve much.